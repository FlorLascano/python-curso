{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python para Finanzas y Ciencia de Datos\n",
    "____\n",
    "\n",
    "# Módulo 4\n",
    "#### Profesor: Jonatan Saúl\n",
    "\n",
    "1. Statistics Concepts\n",
    "2. Portfolio Optimization\n",
    "3. Principal Component Analysis (PCA)\n",
    "4. Value-at-Risk (VaR)\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_intro.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAMOS LAS LIBRERÍAS QUE VAMOS A USAR A LO LARGO DEL MÓDULO.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "from numpy.random import multivariate_normal\n",
    "import yfinance as yf\n",
    "\n",
    "import scipy.stats as scs\n",
    "import scipy.optimize as sco\n",
    "import scipy.interpolate as sci\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#import functions as f \n",
    "\n",
    "import random\n",
    "random.seed(1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some important statistics concepts\n",
    "\n",
    "### Random variables and probability functions\n",
    "\n",
    "A **random variable** is a function that maps the outcomes of random phenomena to a unique numerical value.\n",
    "\n",
    "A random variable can be **discrete** or **continuous**.  \n",
    "+ A discrete random variable $X$ has a countable number of possible values, e.g: rolling a dice. \n",
    "+ A continuous random variable $X$ takes all values in a given interval of numbers, e.g: the returns of a risky asset.\n",
    "\n",
    "The function that relates outcomes to their probabilities in continuous random variables is called **probability density function (PDF)**.\n",
    "\n",
    "The **distribution function** shows the probability of receiving an outcome or a lower one, that is, it shows the cumulative probabilities.\n",
    "\n",
    "Let $X$ be a random variable, $q$ certain realization of that random variable, $f(x)$ the probability density function and $F(x)$ the distribution probability, then the probability that $X \\leq q$ is:\n",
    "\n",
    "$$ F(q) = \\int_{-\\infty}^{q}f(x)dx$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=\"center\"> Density function and Boxplot </h4>\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Boxplot_vs_PDF.svg/800px-Boxplot_vs_PDF.svg.png' width=\"40%\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moments of a random variable\n",
    "\n",
    "**Expectation**\n",
    "\n",
    "In probability theory, the expected value of a random variable $X$, $E(X)$ or $E[X]$, is a generalization of the weighted average, and is intuitively the arithmetic mean of a large number of independent realizations of $X$.\n",
    "\n",
    "The expectation of $X$, $\\mu$, is the expected value or mean of the variable. It is defined by:\n",
    "\n",
    "$$\\mu_x = E(X) = \\int_{-\\infty}^{\\infty}x f(x) dx$$\n",
    "\n",
    "or\n",
    "$$ \\mu_x=\\sum_{i=1}^{N}X_i Pr(X_i)$$\n",
    "in the discrete case. \n",
    "\n",
    "\n",
    "\n",
    "**Variance**\n",
    "\n",
    "The variance of $X$ measures the spread of the variable around its mean. It is defined by:\n",
    "\n",
    "$$\\sigma^2_x = E \\left[ (X - \\mu)^2\\right] = \\int_{-\\infty}^{\\infty}(x - \\mu)^2 f(x) dx$$\n",
    "\n",
    "And the discrete case:\n",
    "$$ \\sigma^2_x = \\sum_{i=1}^{N}(X_i-\\mu)^2 Pr(X_i) $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher order moments:\n",
    "\n",
    "The *k-th* moment of a random variable $X$ is defined by:\n",
    "$$m_k' = E(X^k)= \\int_{-\\infty}^\\infty x^k\\,f(x)\\,\\mathrm{d}x $$\n",
    "\n",
    "and the *k-th* centered moment of a random variable is defined by:\n",
    "$$m_k = E\\left[ (X - \\mu) ^k \\right] = \\int_{-\\infty}^\\infty (x - \\mu)^k\\,f(x)\\,\\mathrm{d}x$$\n",
    "\n",
    "Note that the first moment is the mean and the second centered moment is the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skewness** and **Kurtosis** are functions of the third and fourth moments.\n",
    "\n",
    "\n",
    "**Skewness**:\n",
    "It is a measure of the asymmetry of the probability distribution of a random variable about its mean. In other words, skewness tells you the amount and direction of skew (departure from horizontal symmetry). \n",
    "\n",
    "$$ \\gamma = \\frac{m_3}{\\sigma^3} =  \\frac{\\int_{-\\infty}^\\infty (x - \\mu)^3\\,f(x)\\,\\mathrm{d}x}{\\left[\\int_{-\\infty}^\\infty (x - \\mu)^2\\,f(x)\\,\\mathrm{d}x\\right]^{\\frac{3}{2}}}$$\n",
    "\n",
    "where $ m_{3}$ third centered moment.\n",
    "\n",
    "The skewness value can be positive or negative, or even undefined. If skewness is 0, the data are perfectly symmetrical, although it is quite unlikely for real-world data. \n",
    "As a general rule of thumb:\n",
    "\n",
    " - If $\\gamma $ is less than -1 or greater than 1, the distribution is highly skewed.\n",
    " - If $\\gamma $ is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.\n",
    " - If $\\gamma $ is between -0.5 and 0.5, the distribution is approximately symmetric.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/c/cc/Relationship_between_mean_and_median_under_different_skewness.png' width=\"60%\"/>\n",
    "\n",
    "\n",
    "**Kurtosis**: \n",
    "This statistic tells you the height and sharpness of the central peak, relative to that of a standard bell curve.\n",
    "\n",
    "$$ \\beta = \\frac{m_4}{\\sigma^4} =  \\frac{\\int_{-\\infty}^\\infty (x - \\mu)^4\\,f(x)\\,\\mathrm{d}x}{\\left[\\int_{-\\infty}^\\infty (x - \\mu)^2\\,f(x)\\,\\mathrm{d}x\\right]^{2}}$$\n",
    "\n",
    "\n",
    " - If the $\\beta$ equals 3, the distribution is normal (mesokurtic).\n",
    " - If the $\\beta$ is less than 3, the distribution is platykurtic.\n",
    " - If the $\\beta$ is greater than 3, the distribution is leptokurtic.\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/1600/1*Nqu07THa7APRTOF7kaVr5Q.jpeg' width='40%'/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample moments\n",
    "\n",
    "When we collect date to study a random variable, what we got is the realization of that variable for each moment or individual. The true parameters of the variable in the population are unknown so we have to estimate them using the collected data: the sample.\n",
    "\n",
    "\n",
    "#### Sample Mean:\n",
    "$$\\hat{\\mu} = \\dfrac{1}{n} \\sum_{i=1}^nX_i$$\n",
    "\n",
    "#### Sample Variance:\n",
    "\n",
    "If $\\mu$ is known, we can compute the sample variance by:\n",
    "\n",
    "$$\\hat{\\sigma}^2= \\dfrac{1}{N}\\sum_{i=1}^N (x_i - \\mu)^2$$\n",
    "\n",
    "In the more realistic case, in which $\\mu$ is unknown we have to use the sample mean and adjust the formula in order to find the unbiased estimator for $\\sigma^2$:\n",
    "\n",
    "$$\\hat{\\sigma}^2= \\dfrac{1}{N-1}\\sum_{i=1}^N (x_i - \\hat{\\mu})^2$$\n",
    "\n",
    "#### Sample Standard Deviation:\n",
    "$$\\hat{\\sigma} = \\sqrt{\\hat{\\sigma}^2}$$\n",
    "\n",
    "\n",
    "#### Sample Skewness:\n",
    "$$ \\hat{\\gamma} = \\frac{\\sum_{i=1}^{N}(X_i-\\hat{\\mu})^3}{N\\hat{\\sigma}^3}$$\n",
    "\n",
    "#### Sample Kurtosis:\n",
    "$$ \\hat{\\beta} = \\frac{\\sum_{i=1}^{N}(X_i-\\hat{\\mu})^4}{N\\hat{\\sigma}^4}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal distribution\n",
    "The normal distribution is the most commonly used distribution mainly beacuse is more convenient to work with than most other distributions, and it is completely described by the first and second moments.\n",
    "\n",
    "$X$ is normally distributed if it has the density:\n",
    "\n",
    "$$ f(x; \\mu, \\sigma) = \\dfrac{1}{\\sqrt{2\\pi}\\sigma} \\exp \\left[ - \\dfrac{1}{2} \\left( \\dfrac{x - \\mu}{\\sigma}\\right)^2\\right]$$\n",
    "\n",
    "and we write $X \\sim N (\\mu , \\sigma^2)$.\n",
    "\n",
    "The normal distribution is unimiodal, symmetric and centered on $\\mu$. The variance, $\\sigma^2$, governs the dispertion of the distribution.\n",
    "\n",
    "<h4 align=\"center\"> Probability density function </h4>\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/7/74/Normal_Distribution_PDF.svg' width=\"50%\" align=\"center\"/>\n",
    "\n",
    "<h4 align=\"center\"> Cumulative distribution function </h4>\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/c/ca/Normal_Distribution_CDF.svg' width=\"50%\" align=\"center\"/>\n",
    "\n",
    "\n",
    "\n",
    "**Standard normal distribution**: Is the name given to the normal distribution with mean zero and unit variance, that is: $X \\sim N (0,1) $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other distributions:\n",
    " - Student's $t$-distribution\n",
    " - Uniform distribution\n",
    " - Chi-square distribution\n",
    " \n",
    "We can make use of numpy.random to simulate each type of random variable and see how their distributions look like.\n",
    "\n",
    "https://www.w3schools.com/python/numpy_random.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Normal\n",
    "norm = np.random.standard_normal(10000)\n",
    "print('-'*100)\n",
    "print('Simulating Standard Normal Variable')\n",
    "print(type(norm))\n",
    "print(np.shape(norm))\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student t\n",
    "t = np.random.standard_t(5,10000)\n",
    "\n",
    "#Uniform\n",
    "unif = np.random.uniform(-1,1,10000)\n",
    "\n",
    "#Chi square\n",
    "chi = np.random.chisquare(2, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have generated 10000 observations of each random variable.\n",
    "\n",
    "Each distribution has some **parameters** that define it. For instance, \n",
    "+ the normal distribution is defined by its mean and variance, \n",
    "+ the Student's t and Chi square distributions are defined by their degree of freedom, and \n",
    "+ the uniform distribution is defined by its minimum and maximum values.\n",
    "\n",
    "The process of generating these many observations is known as **Monte Carlo simulations**. Let's see how these variables look like.\n",
    "\n",
    "We can use gaussian_kde (kernel density estimation) to estimate the probability density function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_density = gaussian_kde(norm) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.linspace.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = np.linspace(min(norm), max(norm)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,6))\n",
    "\n",
    "plt.hist(norm, color = 'blue', bins = 50, density = True, alpha = 0.8)\n",
    "plt.plot(xn, norm_density(xn), color = 'black', lw=2)\n",
    "plt.title('Standard normal')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More variables...\n",
    "\n",
    "t_density = gaussian_kde(t)\n",
    "xt = np.linspace(min(t), max(t))\n",
    "\n",
    "unif_density = gaussian_kde(unif)\n",
    "xu = np.linspace(min(unif), max(unif))\n",
    "\n",
    "chi_density = gaussian_kde(chi)\n",
    "xch= np.linspace(min(chi), max(chi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (22,9))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(norm, color = 'blue', bins = 50, density = True, alpha = 0.8)\n",
    "plt.plot(xn, norm_density(xn), color = 'black', lw=2)\n",
    "plt.title('Standard normal')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(t, color = 'orange', bins = 50, density = True, alpha = 0.8 )\n",
    "plt.plot(xt, t_density(xt), color = 'black', lw=2)\n",
    "plt.title('Student-t')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(unif, color = 'green', bins = 50, density = True, alpha = 0.8)\n",
    "plt.plot(xu, unif_density(xu), color = 'black', lw=2)\n",
    "plt.title('Uniform')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(chi, color = 'red', bins = 50, density = True, alpha = 0.8)\n",
    "plt.plot(xch, chi_density(xch), color = 'black', lw=2)\n",
    "plt.title('Chi square')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work with the standard normal variable. \n",
    "\n",
    "We know that a standard normal distribution has mean = 0 and standard deviation = 1. \n",
    "\n",
    "Let's calculate those moments using our generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_hat = norm.mean()\n",
    "sigma_hat = norm.std()\n",
    "\n",
    "print(\"The sample mean is \" + str(np.round(mu_hat,4)))\n",
    "print(\"The sample standard deviation is \" + str(np.round(sigma_hat,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had all the population data, then we would have the true mean and variance of the variable. \n",
    "\n",
    "Since we are only working with a portion of that population (the sample), we will always have some estimation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness and kurtosis\n",
    "\n",
    "We can also generate distributions using *scipy.stats*. \n",
    "\n",
    "The module *skewnorm* allows us to create asymmetric distributions. \n",
    "\n",
    "It takes a real number as the asymmetric parameter. \n",
    "\n",
    "When that number equals zero, the distribution is normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewnorm, t\n",
    "\n",
    "skew_a = [-50, 0, 50]\n",
    "x0 = skewnorm.rvs(skew_a[0], size=10000)\n",
    "x1 = skewnorm.rvs(skew_a[1],size=10000)\n",
    "x2 = skewnorm.rvs(skew_a[2], size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simulating asymmetric distributions')\n",
    "print(type(x1))\n",
    "print(np.shape(x1))\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (22,9))\n",
    "fig.suptitle('Different levels of skewness', fontsize = 16)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(x0, color = 'orange', label='Negative Skew', bins = 30)\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'upper left')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(x1, color = 'blue', label='Normal', bins = 30)\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(x2, color = 'green', label='Positive Skew', bins = 30)\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create distributions with different levels of kurtosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [5, 10, 200] \n",
    "\n",
    "y0 = t.rvs(df[0], size=10000, loc =0)\n",
    "y1 = t.rvs(df[1], size=10000, loc =0)\n",
    "y2 = t.rvs(df[2], size=10000, loc =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simulating distributions with different levels of kurtosis')\n",
    "print(type(y1))\n",
    "print(np.shape(y1))\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = 2000\n",
    "xlim = 8\n",
    "\n",
    "fig = plt.figure(figsize = (22,9))\n",
    "fig.suptitle('Different levels of kurtosis', fontsize = 16)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(y0, color = 'orange', label='t with 5 df', bins = 50)\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'best')\n",
    "plt.ylim(0,ylim)\n",
    "plt.xlim(-xlim,xlim)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(y1, color = 'blue', label='t with 10 df', bins = 50)\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'best')\n",
    "plt.ylim(0,ylim)\n",
    "plt.xlim(-xlim,xlim)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(y2, color = 'green', label='t with 200 df', bins = 50)\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'best')\n",
    "plt.ylim(0,ylim)\n",
    "plt.xlim(-xlim,xlim)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio optimization: Modern Portfolio Theory\n",
    "\n",
    "* * *\n",
    "\n",
    "In 1952, Harry Markowitz proposed a normative model for selection of risky assets. \n",
    "\n",
    "The basic assumption was that inversors care about the **return** and **risk** of their portfolios. \n",
    "\n",
    "His great contribution was to define **return** as the mean of the probability distribution of assets returns and **risk** as the variance of that distribution.\n",
    "\n",
    "By defining risk as variance, Markowitz was able to quantify precisely the gains of diversification: through diversification, risk can be reduced (though not eliminated) without changing the expected portfolio return.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic theory\n",
    "\n",
    "### The expected return on a portfolio\n",
    "\n",
    "The return of a risky asset *j* will be defined as\n",
    "\n",
    "$$ R_{j,t,s} = \\dfrac{P_{j,t,s} - P_{j,t-1}}{P_{j,t-1}}$$\n",
    "\n",
    "Where $P$ denotes the price of the asset, $t-1$ is the date in which the asset is bought, $t$ is the date in which the asset is sold and $s$ denote the state of nature.\n",
    "\n",
    "For simplicity, we will asume that the return's distribution is discrete and $\\pi_s$ is the probability of each state of the nature. Thus, its expectation equals:\n",
    "\n",
    "$$E(R_{j,t}) = \\sum_{s = 1}^S \\pi_s R_{j,t,s}$$\n",
    "\n",
    "Consider a portfolio consisting of N assets, and let $\\omega_j$ be the weight of each asset in the cost of the portfolio, then the return of this portfolio is:\n",
    "\n",
    "$$R_{p,t,s}  = \\sum_{j=1}^N \\omega_j R_{j,t,s}$$\n",
    "\n",
    "That is, the return on a portfolio is a weithed average of the returns of the assets in the portfolio.\n",
    "\n",
    "The portfolio's expected return is also the weigthed average of the asset expected returns:\n",
    "\n",
    "$$E(R_p) = \\sum_{j=1}^N\\omega_jE(R_j)$$\n",
    "\n",
    "\n",
    "### Measurement of risk and diversification\n",
    "\n",
    "The variance of an asset return equals:\n",
    "\n",
    "$$\\sigma_j^2 = E [R_j - E(R_j)]^2 = \\sum_{s=1}^S \\pi_s [R_j - E(R_j)]^2$$\n",
    "\n",
    "\n",
    "In order to understand how can a portfolio reduce its risk through diversification, let's asume we only have two assets. The variance of this two-assets portfolio is:\n",
    "\n",
    "$$ \\sigma^2_p = \\omega^2\\sigma_1^2 + (1 - \\omega)^2\\sigma_2^2 + 2 \\omega(1 - \\omega)\\sigma_{12}$$\n",
    "\n",
    "$$ \\sigma^2_p = \\omega^2\\sigma_1^2 + (1 - \\omega)^2\\sigma_2^2 + 2 \\omega(1 - \\omega)\\rho_{12}\\sigma_1\\sigma_2$$\n",
    "\n",
    "Note that the variance of the portfolio depends on the correlation between the assets. We will explore how different correlations have a different impact on the variance of the portfolio and therefore in diversification gains.\n",
    "\n",
    "\n",
    "The entire model is described by mean and variance of the assets. \n",
    "\n",
    "Therefore we are necessarily assuming that no other statistics are necessary to describe the distribution of end-of-period wealth. \n",
    "\n",
    "Since normal distribution is determined by mean and variance, if returns are normal distributed then we can fully describe the investment opportunity set. We will need to verify this condition and in case it doesn't hold we will have to assume so.\n",
    "\n",
    "We define the **invesment opportunity set** as the pairs of mean and standard deviation that can be achived by inversing arbitrary amounts in the *N* risky assets. The **frontier** of the invesment opportunity set is defined as the set of portfolios with minimum variance among all portfolios with equal expected returns.\n",
    "\n",
    "\n",
    "### Sharpe ratio\n",
    "\n",
    "In order to be capable to compare between different investment choices, we need a risk-adjusted return measure. Sharpe ratio is defined as the excess portfolio return over the risk-free rate relative to its standard deviation:\n",
    "\n",
    "$$ S = \\dfrac{E(R_p) - R_f}{\\sigma_p}$$\n",
    "\n",
    "where $R_f$ is the risk free rate of the market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix notation\n",
    "\n",
    "For computational purposes it is much more useful to have a matrix representation of the above measures of the porfolio.\n",
    "\n",
    "The expected return of the porfolio is:\n",
    "\n",
    "$$E(R_p) = \\omega' E(R)$$\n",
    "\n",
    "where $E(R)$ is the vector containing the expected returns of all the assets and $\\omega$ is the vector of weights.\n",
    "\n",
    "\n",
    "The variance of the portfolio is:\n",
    "\n",
    "$$\\sigma_p^2 = \\omega' \\Sigma \\omega$$\n",
    "\n",
    "where $\\Sigma$ is the covariance matrix of the returns:\n",
    "\n",
    "$$ \\Sigma =  \\begin{bmatrix} \\sigma_1^2 & \\sigma_{1,2} & \\dots & \\sigma_{1,N}\\\\\n",
    "\\sigma_{2,1} & \\sigma_{2}^2 & \\dots & \\sigma_{2,N}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\sigma_{N,1} & \\sigma_{N,2} & \\dots & \\sigma_{N}^2\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different correlations\n",
    "\n",
    "Supose we have 2 normaly distributed assets.  We want to explore how a different correlation between them can generate different results in terms of diversification gains.\n",
    "\n",
    "Recall the variance of the portfolio is\n",
    "\n",
    "\n",
    "$$ \\sigma^2_p = \\omega^2\\sigma_1^2 + (1 - \\omega)^2\\sigma_2^2 + 2 \\omega(1 - \\omega)\\rho_{12}\\sigma_1\\sigma_2$$\n",
    "\n",
    "Let's asume for simplicity that both assets have the same variance. Then,\n",
    "\n",
    "$$ \\sigma^2_p = \\left[1 - 2\\omega(1 - \\omega)(1 - \\rho_{12})\\right]\\sigma^2$$\n",
    "\n",
    "This allows as to visualize the reduction of the portfolio variance compared to the variance of the assets, i.e. diversification gains.\n",
    "\n",
    "\n",
    "\n",
    "#### Case 1: Uncorrelated returns ($\\rho =0$)\n",
    "\n",
    "The maximum reduction in variance is achived when the inversment is equally split across securities ($\\omega = 1/2$), which gives:\n",
    "\n",
    "$$ \\sigma^2_p = [1 - 2\\omega(1 - \\omega)]\\sigma^2$$\n",
    "\n",
    "$$\\sigma^2_p = \\left[1 - \\dfrac{1}{2}\\right]\\sigma^2  = \\dfrac{1}{2}\\sigma^2$$\n",
    "\n",
    "This means that by combining the two assets, variance can be reduced to half of individual variances. \n",
    "\n",
    "This makes sense if we think of what a zero correlation means. Think for instance of tossing a coin twice, where the outcome of each toss is independent of the other. \n",
    "\n",
    "If instead of betting everything on a single toss we split out money into two toss, some losses will be offset by gains on the other gamble, but we may still lose on boths. \n",
    "\n",
    "Risk is reduced but not eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the same variances for both assets and equal to 1. This will imply that $\\rho_{12} = \\dfrac{cov_{12}}{var_1 var_2} = cov_{12}$. Let's also assume that the assets means are 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_weights(n):\n",
    "    k = np.random.rand(n)\n",
    "    return k / sum(k)\n",
    "\n",
    "def portf_mean(w, mean):\n",
    "    mu = w.dot(mean)\n",
    "    return mu\n",
    "    \n",
    "def portf_var(w, cov_matrix):\n",
    "    \n",
    "    sigma = np.diagonal(w.dot(cov_matrix).dot(w.T))\n",
    "    return sigma    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((500,2))\n",
    "for i in range(len(weights)):\n",
    "    weights[i] = rand_weights(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(weights))\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = 1\n",
    "var2 = 1\n",
    "var= [var1, var2]\n",
    "mean = [1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,6))\n",
    "plt.scatter(var, mean, marker='o',alpha = 0.8, label = 'Efficient part of the frontier')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Variance')\n",
    "plt.ylabel('Mean')\n",
    "plt.xlim(-0.01)\n",
    "plt.legend(loc='lower left', fontsize = 13)\n",
    "plt.title('Mean-variance frontiers for two asset with correlation ??', fontsize = 15)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python zip() Function https://www.w3schools.com/python/ref_func_zip.asp\n",
    "\n",
    "We use zip(X, Y) to create an iterator that produces tuples of the form (x, y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = zip(mean, var)\n",
    "list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var_plot(mean, var, corr):\n",
    "    fig = plt.figure(figsize = (22,9))              \n",
    "    plt.scatter(var, mean, marker='o',alpha = 0.8, label = 'Efficient part of the frontier')\n",
    "    \n",
    "    if corr == 1:\n",
    "        for mu, sigma in zip(mean, var):\n",
    "            if mu < max(mean):\n",
    "                plt.scatter(sigma, mu, color = 'tomato')\n",
    "        plt.scatter(x= var[np.argmax(mean)], y = max(mean), \n",
    "                    lw = 8, label = 'Minimum variance achieved',  marker= \"X\", c ='gold', s=70)\n",
    "\n",
    "    else:\n",
    "        for mu, sigma in zip(mean, var):\n",
    "            if mu < mean[np.argmin(var)]:\n",
    "                plt.scatter(sigma, mu, color = 'tomato')\n",
    "        plt.scatter(x= min(var), y = mean[np.argmin(var)], marker= \"X\",\n",
    "                   lw = 8, label = 'Minimum variance achieved', c ='gold', s=70)                \n",
    "            \n",
    "    plt.xlabel('Variance')\n",
    "    plt.ylabel('Mean')\n",
    "    plt.xlim(-0.01)\n",
    "    plt.legend(loc='lower left', fontsize = 13)\n",
    "    plt.title('Mean-variance frontiers for two asset with correlation '+ str(corr), fontsize = 15)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Case 1\n",
    "cov1 = 0\n",
    "cov_matrix1 = np.asarray([[var1, cov1],\n",
    "              [cov1, var2]])\n",
    "case1 = multivariate_normal(mean, cov_matrix1, size = 100)\n",
    "mean_p1= portf_mean(weights, mean)\n",
    "var_p1 = portf_var(weights, cov_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_p1[np.argmin(var_p1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_var_plot(mean_p1, var_p1, corr = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: Imperfectly positively correlated returns ($\\rho =0.5$)\n",
    "\n",
    "$$ \\sigma^2_p = [1 - \\omega(1 - \\omega)]\\sigma^2$$\n",
    "\n",
    "Again, the maximum reduction in variance is achieved when the investment is equally split aross assets, but now:\n",
    "\n",
    "$$ \\sigma^2_p = \\left[1 - \\dfrac{1}{4}\\right]\\sigma^2 = \\dfrac{3}{4}\\sigma^2$$\n",
    "\n",
    "Only a quarter of individual variance can be reduced. Losses are offset by gains but assets returns tend to move in the same direction, so such compensations across assets are less frequent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case 2\n",
    "cov2 = 0.5\n",
    "cov_matrix2 = [[var1, cov2],\n",
    "              [cov2, var2]]\n",
    "case2 = multivariate_normal(mean, cov_matrix2, size = 100)\n",
    "mean_p2= portf_mean(weights, mean)\n",
    "var_p2 = portf_var(weights,cov_matrix2)\n",
    "\n",
    "mean_var_plot(mean_p2, var_p2, corr = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 3: Perfectly positively correlated returns ($\\rho = 1$)\n",
    "\n",
    "$$ \\sigma^2_p = [1 - 2\\omega(1 - \\omega)(1-1)]\\sigma^2 = \\sigma^2$$\n",
    "\n",
    "Since assets always move in the same direction, there is no diversification gains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case 3\n",
    "cov3 = 1\n",
    "cov_matrix3 = [[var1, cov3],\n",
    "              [cov3, var2]]\n",
    "case3 = multivariate_normal(mean, cov_matrix3, size = 100)\n",
    "mean_p3= portf_mean(weights, mean)\n",
    "var_p3 = portf_var(weights, cov_matrix3)\n",
    "\n",
    "mean_var_plot(mean_p3, var_p3, corr = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 4: Imperfectly negatively correlated returns  ($\\rho = -0.5$)\n",
    "\n",
    "$$ \\sigma^2_p = [1 - 3\\omega(1 - \\omega)]\\sigma^2 $$\n",
    "\n",
    "With $\\omega = 1/2$:\n",
    "\n",
    "$$ \\sigma^2_p = \\left[1 - \\dfrac{3}{4}\\right]\\sigma^2 = \\dfrac{1}{4}\\sigma^2$$\n",
    "\n",
    "Losses on one asset are offset by gains on the other. This happens more frequently than in the no correlation case, as asset returns tend to move in opposite directions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case 4\n",
    "cov4 = -0.5\n",
    "cov_matrix4 = [[var1, cov4],\n",
    "              [cov4, var2]]\n",
    "case4 = multivariate_normal(mean, cov_matrix4, size = 100)\n",
    "mean_p4= portf_mean(weights, mean)\n",
    "var_p4 = portf_var(weights, cov_matrix4)\n",
    "\n",
    "mean_var_plot(mean_p4, var_p4, corr = -0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 5: Perfectly negatively correlated returns ($\\rho = -1$)\n",
    "\n",
    "$$ \\sigma^2_p = [1 - 4\\omega(1 - \\omega)(1-1)]\\sigma^2$$\n",
    "\n",
    "Setting $\\omega = 1/2$ we get:\n",
    "\n",
    "$$ \\sigma^2_p = \\left[1 - \\dfrac{4}{4}\\right]\\sigma^2 = 0 $$\n",
    "\n",
    "In this case losses are always compensated with gains so we can completely eliminate variance. Instead of risk diversification, we are actually talking about *risk hedging*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case 5\n",
    "cov5 = -1\n",
    "cov_matrix5 = [[var1, cov5],\n",
    "              [cov5, var2]]\n",
    "case5 = multivariate_normal(mean, cov_matrix5, size = 100)\n",
    "mean_p5= portf_mean(weights, mean)\n",
    "var_p5 = portf_var(weights, cov_matrix5)\n",
    "\n",
    "mean_var_plot(mean_p5, var_p5, corr = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (22,9))              \n",
    "plt.scatter(var_p1, mean_p1, marker='o', lw = 0.1, alpha = 0.8, label = 'Case 1: no correlation')\n",
    "plt.scatter(var_p2, mean_p2, marker='o', lw = 0.1, alpha = 0.8, label = 'Case 2: 0.5 correlation') \n",
    "plt.scatter(var_p3, mean_p3, marker='o', lw = 0.1, alpha = 0.8, label = 'Case 3: perfect positive correlation') \n",
    "plt.scatter(var_p4, mean_p4, marker='o', lw = 0.1, alpha = 0.8, label = 'Case 4: -0.5 correlation') \n",
    "plt.scatter(var_p5, mean_p5, marker='o', lw = 0.1, alpha = 0.8, label = 'Case 5: perfect negative correlation') \n",
    "\n",
    "plt.xlabel('Variance', fontsize = 15)\n",
    "plt.ylabel('Mean', fontsize = 15)\n",
    "plt.xlim(0)\n",
    "plt.legend(loc='lower left', fontsize = 15)\n",
    "plt.grid(True)\n",
    "plt.title('Mean-variance frontiers for different correlations', fontsize = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returns_plot(cov):\n",
    "    cov_matrix = np.asarray([[1, cov],\n",
    "              [cov, 1]])\n",
    "    mean = [0,0]\n",
    "    case = multivariate_normal(mean, cov_matrix, size = 1000)\n",
    "    \n",
    "    fig = plt.figure(figsize = (10,7))\n",
    "    \n",
    "    plt.scatter(x=case[:,0], y=case[:,1])\n",
    "    plt.xlabel('Asset 1 returns')\n",
    "    plt.ylabel('Asset 2 returns')\n",
    "    plt.title('Scatter plot of assets returns with correlation '+ str(cov))\n",
    "    plt.xlim(-4,4)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = float(input(\"Correlation: \"))\n",
    "if cor> 1 or cor< -1:\n",
    "    print('Error! Correlation must be between -1 and 1')\n",
    "else:\n",
    "    returns_plot(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add a third asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((2000,3))\n",
    "for i in range(len(weights)):\n",
    "    weights[i] = rand_weights(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noa = 3\n",
    "n_obs = 10000\n",
    "\n",
    "return_vec = np.random.randn(noa, n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(return_vec, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(return_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmean= portf_mean(weights, np.mean(return_vec, axis = 1))\n",
    "pvar = portf_var(weights, np.cov(return_vec))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (22,9))          \n",
    "plt.scatter(pvar, pmean, marker='o', lw = 0.1, alpha = 0.8, c = pmean/np.sqrt(pvar))\n",
    "plt.grid(True)\n",
    "plt.title('Mean-variance of a portfolio with three assets', fontsize = 17)\n",
    "plt.xlabel('Variance', fontsize = 14)\n",
    "plt.ylabel('Mean', fontsize = 14)\n",
    "plt.colorbar(label = 'Sharpe ratio')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows that when we invest in the three assets simultaneously, not only do we have access to more combinations of mean and variance, but also to better combinations. By adding a third asset to the portfolio, we profit from further diversification gains.\n",
    "\n",
    "When calculating the Shapre ratio we assume $R_f = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
